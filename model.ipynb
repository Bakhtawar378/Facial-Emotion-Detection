{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8643214,"sourceType":"datasetVersion","datasetId":5176472}],"dockerImageVersionId":30554,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-08T17:01:27.512187Z","iopub.execute_input":"2023-09-08T17:01:27.512838Z","iopub.status.idle":"2023-09-08T17:02:53.514817Z","shell.execute_reply.started":"2023-09-08T17:01:27.512806Z","shell.execute_reply":"2023-09-08T17:02:53.513367Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.layers import Dense\nfrom keras.layers import Flatten\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dropout\nfrom keras import models\nfrom keras import layers\nfrom keras.layers import BatchNormalization\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras import models\nfrom keras import layers\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport os\nimport seaborn as sns\nfrom keras.regularizers import l2\nfrom tensorflow.keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:57:13.290805Z","iopub.execute_input":"2024-06-09T04:57:13.291076Z","iopub.status.idle":"2024-06-09T04:57:24.897080Z","shell.execute_reply.started":"2024-06-09T04:57:13.291051Z","shell.execute_reply":"2024-06-09T04:57:24.896199Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"epochs = 50\nbatch_size = 64\nimg_rows, img_cols = 48, 48\nclasses = ['angry', 'disgust','fear','happy','neutral','sad','surprise']\n# classes = ['disgust', 'fear', 'happy','pain', 'sad']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:57:52.524823Z","iopub.execute_input":"2024-06-09T04:57:52.525449Z","iopub.status.idle":"2024-06-09T04:57:52.530388Z","shell.execute_reply.started":"2024-06-09T04:57:52.525416Z","shell.execute_reply":"2024-06-09T04:57:52.529453Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\n\ndef get_data(batch_size, target_size, train_path, test_path):\n    train_datagen = ImageDataGenerator(\n        validation_split=0.2,\n        rescale=1./255,\n        featurewise_center=False,\n        featurewise_std_normalization=False,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        preprocessing_function=lambda img: cv2.resize(img, (224,224), interpolation=cv2.INTER_LINEAR)\n        \n\n    )\n\n    validation_datagen = ImageDataGenerator(\n        validation_split=0.2,\n        rescale=1./255\n    )\n\n    train_generator = train_datagen.flow_from_directory(\n        train_path,\n        batch_size=batch_size,\n        target_size=target_size,\n        color_mode='rgb',\n        shuffle=True,\n        class_mode='categorical',\n        subset='training'\n        \n        \n    )  # Set as training data\n\n\n    validation_generator = validation_datagen.flow_from_directory(\n        test_path,\n        batch_size=batch_size,\n        target_size=target_size,\n        color_mode='rgb',\n        shuffle=False,\n        class_mode='categorical',\n        subset='validation'\n        \n    )  # Set as validation data\n\n    return train_generator, train_generator.labels, validation_generator, validation_generator.labels\n# function to plot the confusion matrix\ndef plot_confusion_matrix(classes, model, model_name):\n    batch_size=32\n    num_of_test_samples = 4941\n    target_names =classes\n    #Confution Matrix and Classification Report\n    Y_pred = model.predict(validation_generator, num_of_test_samples // batch_size)\n    y_pred = np.argmax(Y_pred, axis=1)\n    print('Confusion Matrix')\n    cm = confusion_matrix(validation_generator.classes, y_pred)\n    print(cm)\n    print('Classification Report')\n    print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n    # Normalise\n    cmn = cm.astype('float') / cm.sum(axis=1)\n    fig, ax = plt.subplots(figsize=(20,7))\n\n    sns.heatmap(cmn, center=0, annot=True, fmt='.2f', linewidths=1,  xticklabels=target_names, yticklabels=target_names)\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.title('cofusion_matrix of **' + f'( {model_name} )**')\n   \n    plt.show(block=False)\n    plt.show()\n\n\n#function to graph the accuracy and loss\ndef plot_graph(history, model_name):\n    f, ax = plt.subplots()\n    ax.plot([None] + history.history['accuracy'], 'o-')\n    ax.plot([None] + history.history['val_accuracy'], 'x-')\n    # Plot legend and use the best location automatically: loc = 0.\n    ax.legend(['Train acc', 'Validation acc'], loc = 0)\n    ax.set_title('Training/Validation acc per Epoch '+f'({model_name})')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Accuracy')\n\n \n    plt.show()\n\n    f, ax = plt.subplots()\n    ax.plot([None] + history.history['loss'], 'o-')\n    ax.plot([None] + history.history['val_loss'], 'x-')\n\n    # Plot legend and use the best location automatically: loc = 0.\n    ax.legend(['Train loss', \"Val loss\"], loc = 1)\n    ax.set_title('Training/Validation Loss per Epoch '+f'({model_name})')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss')\n   \n    plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:57:54.954455Z","iopub.execute_input":"2024-06-09T04:57:54.954867Z","iopub.status.idle":"2024-06-09T04:57:55.196292Z","shell.execute_reply.started":"2024-06-09T04:57:54.954837Z","shell.execute_reply":"2024-06-09T04:57:55.195499Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,GlobalMaxPooling2D,Dense,Reshape, Add, Activation,Permute,Lambda,Concatenate, Conv2D,multiply,Layer\n\n\nclass CBAMBlock(keras.layers.Layer):\n    def __init__(self, ratio=64,name='cbamblock'):\n        super().__init__(name=name)\n        self.ratio = ratio\n\n    @tf.function\n    def cbam_block(self, cbam_feature):\n        cbam_feature = self.channel_attention(cbam_feature)\n        cbam_feature = self.spatial_attention(cbam_feature)\n        return cbam_feature\n\n    def channel_attention(self, input_feature):\n        channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n        channel = input_feature.shape[channel_axis]\n\n        shared_layer_one = Dense(\n            channel // self.ratio,\n            activation='relu',\n            kernel_initializer='he_normal',\n            use_bias=True,\n            bias_initializer='zeros',\n        )\n        shared_layer_two = Dense(\n            channel,\n            kernel_initializer='he_normal',\n            use_bias=True,\n            bias_initializer='zeros',\n        )\n\n        avg_pool = GlobalAveragePooling2D()(input_feature)\n        avg_pool = Reshape((1, 1, channel))(avg_pool)\n        assert avg_pool.shape[1:] == (1, 1, channel)\n        avg_pool = shared_layer_one(avg_pool)\n        assert avg_pool.shape[1:] == (1, 1, channel // self.ratio)\n        avg_pool = shared_layer_two(avg_pool)\n        assert avg_pool.shape[1:] == (1, 1, channel)\n\n        max_pool = GlobalMaxPooling2D()(input_feature)\n        max_pool = Reshape((1, 1, channel))(max_pool)\n        assert max_pool.shape[1:] == (1, 1, channel)\n        max_pool = shared_layer_one(max_pool)\n        assert max_pool.shape[1:] == (1, 1, channel // self.ratio)\n        max_pool = shared_layer_two(max_pool)\n        assert max_pool.shape[1:] == (1, 1, channel)\n\n        cbam_feature = Add()([avg_pool, max_pool])\n        cbam_feature = Activation('sigmoid')(cbam_feature)\n\n        if tf.keras.backend.image_data_format() == \"channels_first\":\n            cbam_feature = Permute((3, 1, 2))(cbam_feature)\n\n        return multiply([input_feature, cbam_feature])\n\n    def spatial_attention(self, input_feature):\n        kernel_size = 7\n\n        if tf.keras.backend.image_data_format() == \"channels_first\":\n            channel = input_feature.shape[1]\n            cbam_feature = Permute((2, 3, 1))(input_feature)\n        else:\n            channel = input_feature.shape[-1]\n            cbam_feature = input_feature\n\n        avg_pool = Lambda(lambda x: tf.reduce_mean(x, axis=3, keepdims=True))(cbam_feature)\n        assert avg_pool.shape[-1] == 1\n        max_pool = Lambda(lambda x: tf.reduce_max(x, axis=3, keepdims=True))(cbam_feature)\n        assert max_pool.shape[-1] == 1\n        concat = Concatenate(axis=3)([avg_pool, max_pool])\n        assert concat.shape[-1] == 2\n        cbam_feature = Conv2D(\n            filters=1,\n            kernel_size=kernel_size,\n            strides=1,\n            padding='same',\n            activation='sigmoid',\n            kernel_initializer='he_normal',\n            use_bias=False,\n        )(concat)\n        assert cbam_feature.shape[-1] == 1\n\n        if tf.keras.backend.image_data_format() == \"channels_first\":\n            cbam_feature = Permute((3, 1, 2))(cbam_feature)\n\n        return multiply([input_feature, cbam_feature])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:58:05.291390Z","iopub.execute_input":"2024-06-09T04:58:05.292082Z","iopub.status.idle":"2024-06-09T04:58:05.312297Z","shell.execute_reply.started":"2024-06-09T04:58:05.292035Z","shell.execute_reply":"2024-06-09T04:58:05.311425Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply\n\ndef se_block(inputs, ratio=4, pooling_type='avg'):\n    filters = inputs.shape[-1]\n    se_shape = (1, 1, filters)\n    \n    se = GlobalAveragePooling2D()(inputs)\n    se = Reshape(se_shape)(se)\n    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n    se = Dense(filters, activation='hard_sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n\n    return multiply([inputs, se])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:24:33.206124Z","iopub.execute_input":"2023-10-27T02:24:33.206915Z","iopub.status.idle":"2023-10-27T02:24:33.213463Z","shell.execute_reply.started":"2023-10-27T02:24:33.206883Z","shell.execute_reply":"2023-10-27T02:24:33.212397Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tf.keras.utils.custom_object_scope({'SeBlock':se_block})","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:24:40.005629Z","iopub.execute_input":"2023-10-27T02:24:40.006219Z","iopub.status.idle":"2023-10-27T02:24:40.012885Z","shell.execute_reply.started":"2023-10-27T02:24:40.006186Z","shell.execute_reply":"2023-10-27T02:24:40.012072Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<keras.saving.object_registration.CustomObjectScope at 0x7ae5170669b0>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, GlobalAveragePooling2D, Dense, BatchNormalization\n\nfrom keras.models import Model\n# Input layer\ninput_shape = (224, 224, 3)\ninput_layer = Input(shape=input_shape)\n\n# Convolutional layers\nx = Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(input_layer) #conv/s2\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x)#conv dw/s1\nx = Conv2D(64, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x) #conv/s1\nx = BatchNormalization()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu')(x) #conv dw/s2\nx = Conv2D(128, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x) # conv/s1\nx = BatchNormalization()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x)\nx = Conv2D(128, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu')(x)\nx = Conv2D(256, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\n#cbam\n\n#cbam=CBAMBlock()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x) #conv dw/s2\nx = Conv2D(256, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu')(x)\nx = Conv2D(256, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\ncbam=CBAMBlock(name='cbamblock_1')(x)\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(cbam)\nx = Conv2D(512, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x)\nx = Conv2D(512, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x)\nx = Conv2D(512, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\n\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x)\nx = Conv2D(512, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x)\nx = Conv2D(512, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\n#cbam=CBAMBlock(name='cbamblock_2')(x)\n\nx = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu')(x)\nx = Conv2D(1024, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\n\nx = DepthwiseConv2D((3, 3), strides=(1, 1), padding='same', activation='relu')(x)\nx = Conv2D(1024, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6)(x)\nx = BatchNormalization()(x)\n\n#cbam=CBAMBlock(name='cbamblock_3')(x)\n\nx=GlobalAveragePooling2D()(x)\n\nx=Dense(1024, activation='relu')(x)\n\nout= Dense(7, activation='softmax')(x)\n\n# Create the Patch Extraction Block model\nmodel = Model(input_layer, out)\n\n\n\n# Print a summary of the model architecture\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:58:14.412202Z","iopub.execute_input":"2024-06-09T04:58:14.412602Z","iopub.status.idle":"2024-06-09T04:58:16.256198Z","shell.execute_reply.started":"2024-06-09T04:58:14.412568Z","shell.execute_reply":"2024-06-09T04:58:16.252808Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n conv2d (Conv2D)             (None, 112, 112, 32)      896       \n                                                                 \n depthwise_conv2d (Depthwise  (None, 112, 112, 32)     320       \n Conv2D)                                                         \n                                                                 \n conv2d_1 (Conv2D)           (None, 112, 112, 64)      2112      \n                                                                 \n batch_normalization (BatchN  (None, 112, 112, 64)     256       \n ormalization)                                                   \n                                                                 \n depthwise_conv2d_1 (Depthwi  (None, 56, 56, 64)       640       \n seConv2D)                                                       \n                                                                 \n conv2d_2 (Conv2D)           (None, 56, 56, 128)       8320      \n                                                                 \n batch_normalization_1 (Batc  (None, 56, 56, 128)      512       \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_2 (Depthwi  (None, 56, 56, 128)      1280      \n seConv2D)                                                       \n                                                                 \n conv2d_3 (Conv2D)           (None, 56, 56, 128)       16512     \n                                                                 \n batch_normalization_2 (Batc  (None, 56, 56, 128)      512       \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_3 (Depthwi  (None, 28, 28, 128)      1280      \n seConv2D)                                                       \n                                                                 \n conv2d_4 (Conv2D)           (None, 28, 28, 256)       33024     \n                                                                 \n batch_normalization_3 (Batc  (None, 28, 28, 256)      1024      \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_4 (Depthwi  (None, 28, 28, 256)      2560      \n seConv2D)                                                       \n                                                                 \n conv2d_5 (Conv2D)           (None, 28, 28, 256)       65792     \n                                                                 \n batch_normalization_4 (Batc  (None, 28, 28, 256)      1024      \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_5 (Depthwi  (None, 14, 14, 256)      2560      \n seConv2D)                                                       \n                                                                 \n conv2d_6 (Conv2D)           (None, 14, 14, 256)       65792     \n                                                                 \n batch_normalization_5 (Batc  (None, 14, 14, 256)      1024      \n hNormalization)                                                 \n                                                                 \n cbamblock_1 (CBAMBlock)     (None, 14, 14, 256)       0         \n                                                                 \n depthwise_conv2d_6 (Depthwi  (None, 14, 14, 256)      2560      \n seConv2D)                                                       \n                                                                 \n conv2d_7 (Conv2D)           (None, 14, 14, 512)       131584    \n                                                                 \n batch_normalization_6 (Batc  (None, 14, 14, 512)      2048      \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_7 (Depthwi  (None, 14, 14, 512)      5120      \n seConv2D)                                                       \n                                                                 \n conv2d_8 (Conv2D)           (None, 14, 14, 512)       262656    \n                                                                 \n batch_normalization_7 (Batc  (None, 14, 14, 512)      2048      \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_8 (Depthwi  (None, 14, 14, 512)      5120      \n seConv2D)                                                       \n                                                                 \n conv2d_9 (Conv2D)           (None, 14, 14, 512)       262656    \n                                                                 \n batch_normalization_8 (Batc  (None, 14, 14, 512)      2048      \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_9 (Depthwi  (None, 14, 14, 512)      5120      \n seConv2D)                                                       \n                                                                 \n conv2d_10 (Conv2D)          (None, 14, 14, 512)       262656    \n                                                                 \n batch_normalization_9 (Batc  (None, 14, 14, 512)      2048      \n hNormalization)                                                 \n                                                                 \n depthwise_conv2d_10 (Depthw  (None, 14, 14, 512)      5120      \n iseConv2D)                                                      \n                                                                 \n conv2d_11 (Conv2D)          (None, 14, 14, 512)       262656    \n                                                                 \n batch_normalization_10 (Bat  (None, 14, 14, 512)      2048      \n chNormalization)                                                \n                                                                 \n depthwise_conv2d_11 (Depthw  (None, 7, 7, 512)        5120      \n iseConv2D)                                                      \n                                                                 \n conv2d_12 (Conv2D)          (None, 7, 7, 1024)        525312    \n                                                                 \n batch_normalization_11 (Bat  (None, 7, 7, 1024)       4096      \n chNormalization)                                                \n                                                                 \n depthwise_conv2d_12 (Depthw  (None, 7, 7, 1024)       10240     \n iseConv2D)                                                      \n                                                                 \n conv2d_13 (Conv2D)          (None, 7, 7, 1024)        1049600   \n                                                                 \n batch_normalization_12 (Bat  (None, 7, 7, 1024)       4096      \n chNormalization)                                                \n                                                                 \n global_average_pooling2d (G  (None, 1024)             0         \n lobalAveragePooling2D)                                          \n                                                                 \n dense (Dense)               (None, 1024)              1049600   \n                                                                 \n dense_1 (Dense)             (None, 7)                 7175      \n                                                                 \n=================================================================\nTotal params: 4,076,167\nTrainable params: 4,064,775\nNon-trainable params: 11,392\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_path='/kaggle/input/newfer/train/'\ntest_path='/kaggle/input/newfer/test/'\ntrain_generator,train_lbl,validation_generator,lbl= get_data(batch_size=64, target_size=(224,224), train_path=train_path,test_path=test_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:58:22.563958Z","iopub.execute_input":"2024-06-09T04:58:22.564317Z","iopub.status.idle":"2024-06-09T04:58:40.267798Z","shell.execute_reply.started":"2024-06-09T04:58:22.564287Z","shell.execute_reply":"2024-06-09T04:58:40.266964Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found 22968 images belonging to 7 classes.\nFound 1432 images belonging to 7 classes.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# adding class weights\nimport numpy as np\nfrom sklearn.utils import class_weight\n\n\n\n# Calculate the class weights\n\nclass_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(lbl), y=lbl)\n# Convert the class weights to a dictionary\nclass_weights_dict = dict(enumerate(class_weights))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T04:59:48.310477Z","iopub.execute_input":"2024-06-09T04:59:48.311218Z","iopub.status.idle":"2024-06-09T04:59:48.321121Z","shell.execute_reply.started":"2024-06-09T04:59:48.311185Z","shell.execute_reply":"2024-06-09T04:59:48.320320Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T05:21:36.152834Z","iopub.execute_input":"2023-09-19T05:21:36.153302Z","iopub.status.idle":"2023-09-19T05:21:36.158978Z","shell.execute_reply.started":"2023-09-19T05:21:36.153262Z","shell.execute_reply":"2023-09-19T05:21:36.157945Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{0: 0.8969202898550724, 1: 1.209035409035409, 2: 0.6866851595006935, 3: 1.5970967741935485, 4: 1.0250517598343685}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nfrom math import pi\nimport keras\nfrom tensorflow.keras.losses import Loss, CategoricalCrossentropy\nfrom tensorflow.keras import initializers\nimport keras.backend as K\n\nclass CombinedLoss(Loss):\n    def __init__(self, lambda_center=0.01, lambda_=0.001, margin=0.35, scale=64,num_classes=7,feature_dim=1024):\n        super(CombinedLoss, self).__init__()\n        self.lambda_center = lambda_center\n        self.lambda_ = lambda_\n        self.margin = margin\n        self.scale = scale\n        self.threshold = tf.math.cos(pi - margin)\n        self.cos_m = tf.math.cos(margin)\n        self.sin_m = tf.math.sin(margin)\n        self.safe_margin = self.sin_m * margin\n        self.feature_dim = feature_dim  # Update feature_dim to 1024\n        self.centers = K.variable(initializers.glorot_uniform()((feature_dim,num_classes)))\n        \n    @tf.function\n    def call(self, y_true, y_pred):\n        # CenterLoss\n        softmax_loss = CategoricalCrossentropy()(y_true, y_pred)\n        centers_batch = tf.gather(self.centers, tf.argmax(y_true, axis=1))\n        center_loss = softmax_loss + 0.01 * (0.5 * self.lambda_center * tf.reduce_sum(tf.square(y_pred - centers_batch)))\n\n        # ArcLoss\n        cos_t = y_pred\n        sin_t = tf.math.sqrt(1 - tf.math.square(cos_t))\n        cos_t_margin = tf.where(cos_t > self.threshold,\n                                cos_t * self.cos_m - sin_t * self.sin_m,\n                                cos_t - self.safe_margin)\n        mask = y_true\n        cos_t_onehot = cos_t * mask\n        cos_t_margin_onehot = cos_t_margin * mask\n        logits = (cos_t + cos_t_margin_onehot - cos_t_onehot) * self.scale\n        arc_loss = tf.nn.softmax_cross_entropy_with_logits(y_true, logits)\n\n        # Combined Loss\n        loss = self.lambda_ * center_loss + self.lambda_ * arc_loss\n        return loss\n\n    \n\n    def get_config(self):\n        config = super(CombinedLoss, self).get_config()\n        config.pop('reduction', None)\n        config.pop('name', None)\n        config.update({\"lambda_center\": self.lambda_center, \n                       \"lambda_\": self.lambda_, \n                       \"margin\": self.margin,\n                       \"scale\": self.scale\n                      })\n        return config\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:11:24.796352Z","iopub.execute_input":"2024-06-09T05:11:24.796808Z","iopub.status.idle":"2024-06-09T05:11:24.810147Z","shell.execute_reply.started":"2024-06-09T05:11:24.796776Z","shell.execute_reply":"2024-06-09T05:11:24.809216Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\ninitial_learning_rate = 0.01\nbatch_size = 128\nweight_decay = 0.0001\n\nopt = SGD(learning_rate=initial_learning_rate,weight_decay=weight_decay,momentum=0.9)\nlr_scheduler = ReduceLROnPlateau(factor=0.5, patience=10, monitor='val_accuracy', mode='max')\n\n\n\nmodel.compile(optimizer = opt , loss=CombinedLoss(), metrics = ['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:11:55.563723Z","iopub.execute_input":"2024-06-09T05:11:55.564432Z","iopub.status.idle":"2024-06-09T05:11:55.595798Z","shell.execute_reply.started":"2024-06-09T05:11:55.564398Z","shell.execute_reply":"2024-06-09T05:11:55.594970Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.preprocessing.image import ImageDataGenerator\nepochs = 100  # will increase late it was 300 n the code\nhistory = model.fit(train_generator,\n                         epochs=epochs,\n                         #steps_per_epoch=620,\n                         validation_data=validation_generator,\n                         class_weight=class_weights_dict,\n                         callbacks=[lr_scheduler])\n\nfeature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)  # Output before the final dense layer\ntrain_features = feature_extractor.predict(train_generator, verbose=1)\nval_features = feature_extractor.predict(validation_generator, verbose=1)\n\n# Assuming train_lbl and lbl are in the correct format for RandomForestClassifier\n# Train the Random Forest classifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_classifier.fit(train_features, train_lbl)\n\n# Predict and evaluate the model using validation data\nval_predictions = rf_classifier.predict(val_features)\nval_accuracy = accuracy_score(lbl, val_predictions)\nprint(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n\n# Visualize the model performance\nplot_graph(history=history, model_name='CNN Model')\nplot_confusion_matrix(classes=classes, model=rf_classifier, model_name='Random Forest')\n\n#visualizing the model \nplot_graph(history=history, model_name='Model')\n#confusion matrix of the model\nplot_confusion_matrix(classes=classes, model=model, model_name='Model')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T05:12:00.047623Z","iopub.execute_input":"2024-06-09T05:12:00.047973Z","iopub.status.idle":"2024-06-09T14:41:00.482622Z","shell.execute_reply.started":"2024-06-09T05:12:00.047944Z","shell.execute_reply":"2024-06-09T14:41:00.481280Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/100\n359/359 [==============================] - 334s 909ms/step - loss: 0.0261 - accuracy: 0.2260 - val_loss: 0.0258 - val_accuracy: 0.2661 - lr: 0.0100\nEpoch 2/100\n359/359 [==============================] - 330s 920ms/step - loss: 0.0258 - accuracy: 0.2605 - val_loss: 0.0258 - val_accuracy: 0.3010 - lr: 0.0100\nEpoch 3/100\n359/359 [==============================] - 327s 912ms/step - loss: 0.0258 - accuracy: 0.2716 - val_loss: 0.0258 - val_accuracy: 0.2947 - lr: 0.0100\nEpoch 4/100\n359/359 [==============================] - 328s 912ms/step - loss: 0.0258 - accuracy: 0.2754 - val_loss: 0.0258 - val_accuracy: 0.2968 - lr: 0.0100\nEpoch 5/100\n359/359 [==============================] - 328s 913ms/step - loss: 0.0258 - accuracy: 0.2797 - val_loss: 0.0257 - val_accuracy: 0.3149 - lr: 0.0100\nEpoch 6/100\n359/359 [==============================] - 329s 916ms/step - loss: 0.0257 - accuracy: 0.2878 - val_loss: 0.0257 - val_accuracy: 0.3212 - lr: 0.0100\nEpoch 7/100\n359/359 [==============================] - 328s 914ms/step - loss: 0.0257 - accuracy: 0.2928 - val_loss: 0.0257 - val_accuracy: 0.3177 - lr: 0.0100\nEpoch 8/100\n359/359 [==============================] - 326s 908ms/step - loss: 0.0257 - accuracy: 0.2975 - val_loss: 0.0257 - val_accuracy: 0.3184 - lr: 0.0100\nEpoch 9/100\n359/359 [==============================] - 328s 914ms/step - loss: 0.0257 - accuracy: 0.3030 - val_loss: 0.0257 - val_accuracy: 0.3184 - lr: 0.0100\nEpoch 10/100\n359/359 [==============================] - 328s 914ms/step - loss: 0.0257 - accuracy: 0.3022 - val_loss: 0.0257 - val_accuracy: 0.3268 - lr: 0.0100\nEpoch 11/100\n359/359 [==============================] - 328s 912ms/step - loss: 0.0257 - accuracy: 0.3054 - val_loss: 0.0257 - val_accuracy: 0.3331 - lr: 0.0100\nEpoch 12/100\n359/359 [==============================] - 330s 918ms/step - loss: 0.0257 - accuracy: 0.3106 - val_loss: 0.0256 - val_accuracy: 0.3331 - lr: 0.0100\nEpoch 13/100\n359/359 [==============================] - 330s 919ms/step - loss: 0.0257 - accuracy: 0.3105 - val_loss: 0.0256 - val_accuracy: 0.3422 - lr: 0.0100\nEpoch 14/100\n359/359 [==============================] - 330s 920ms/step - loss: 0.0256 - accuracy: 0.3133 - val_loss: 0.0256 - val_accuracy: 0.3534 - lr: 0.0100\nEpoch 15/100\n359/359 [==============================] - 330s 920ms/step - loss: 0.0256 - accuracy: 0.3160 - val_loss: 0.0256 - val_accuracy: 0.3485 - lr: 0.0100\nEpoch 16/100\n359/359 [==============================] - 330s 919ms/step - loss: 0.0256 - accuracy: 0.3187 - val_loss: 0.0256 - val_accuracy: 0.3457 - lr: 0.0100\nEpoch 17/100\n359/359 [==============================] - 331s 920ms/step - loss: 0.0256 - accuracy: 0.3194 - val_loss: 0.0255 - val_accuracy: 0.3603 - lr: 0.0100\nEpoch 18/100\n359/359 [==============================] - 332s 924ms/step - loss: 0.0256 - accuracy: 0.3244 - val_loss: 0.0255 - val_accuracy: 0.3464 - lr: 0.0100\nEpoch 19/100\n359/359 [==============================] - 331s 921ms/step - loss: 0.0256 - accuracy: 0.3296 - val_loss: 0.0255 - val_accuracy: 0.3568 - lr: 0.0100\nEpoch 20/100\n359/359 [==============================] - 330s 919ms/step - loss: 0.0255 - accuracy: 0.3301 - val_loss: 0.0254 - val_accuracy: 0.3492 - lr: 0.0100\nEpoch 21/100\n359/359 [==============================] - 329s 916ms/step - loss: 0.0255 - accuracy: 0.3283 - val_loss: 0.0253 - val_accuracy: 0.3666 - lr: 0.0100\nEpoch 22/100\n359/359 [==============================] - 332s 925ms/step - loss: 0.0255 - accuracy: 0.3333 - val_loss: 0.0254 - val_accuracy: 0.3499 - lr: 0.0100\nEpoch 23/100\n359/359 [==============================] - 338s 940ms/step - loss: 0.0254 - accuracy: 0.3332 - val_loss: 0.0253 - val_accuracy: 0.3603 - lr: 0.0100\nEpoch 24/100\n359/359 [==============================] - 345s 961ms/step - loss: 0.0253 - accuracy: 0.3313 - val_loss: 0.0252 - val_accuracy: 0.3485 - lr: 0.0100\nEpoch 25/100\n359/359 [==============================] - 344s 959ms/step - loss: 0.0253 - accuracy: 0.3363 - val_loss: 0.0251 - val_accuracy: 0.3722 - lr: 0.0100\nEpoch 26/100\n359/359 [==============================] - 342s 951ms/step - loss: 0.0251 - accuracy: 0.3421 - val_loss: 0.0253 - val_accuracy: 0.3149 - lr: 0.0100\nEpoch 27/100\n359/359 [==============================] - 339s 943ms/step - loss: 0.0251 - accuracy: 0.3356 - val_loss: 0.0251 - val_accuracy: 0.3408 - lr: 0.0100\nEpoch 28/100\n359/359 [==============================] - 338s 941ms/step - loss: 0.0250 - accuracy: 0.3427 - val_loss: 0.0247 - val_accuracy: 0.3778 - lr: 0.0100\nEpoch 29/100\n359/359 [==============================] - 334s 929ms/step - loss: 0.0249 - accuracy: 0.3467 - val_loss: 0.0251 - val_accuracy: 0.3177 - lr: 0.0100\nEpoch 30/100\n359/359 [==============================] - 327s 910ms/step - loss: 0.0248 - accuracy: 0.3442 - val_loss: 0.0247 - val_accuracy: 0.3652 - lr: 0.0100\nEpoch 31/100\n359/359 [==============================] - 327s 912ms/step - loss: 0.0246 - accuracy: 0.3520 - val_loss: 0.0243 - val_accuracy: 0.3631 - lr: 0.0100\nEpoch 32/100\n359/359 [==============================] - 330s 918ms/step - loss: 0.0246 - accuracy: 0.3467 - val_loss: 0.0255 - val_accuracy: 0.2758 - lr: 0.0100\nEpoch 33/100\n359/359 [==============================] - 329s 916ms/step - loss: 0.0245 - accuracy: 0.3532 - val_loss: 0.0241 - val_accuracy: 0.3771 - lr: 0.0100\nEpoch 34/100\n359/359 [==============================] - 334s 930ms/step - loss: 0.0244 - accuracy: 0.3552 - val_loss: 0.0249 - val_accuracy: 0.3359 - lr: 0.0100\nEpoch 35/100\n359/359 [==============================] - 335s 934ms/step - loss: 0.0243 - accuracy: 0.3544 - val_loss: 0.0240 - val_accuracy: 0.3541 - lr: 0.0100\nEpoch 36/100\n359/359 [==============================] - 342s 952ms/step - loss: 0.0242 - accuracy: 0.3611 - val_loss: 0.0240 - val_accuracy: 0.3715 - lr: 0.0100\nEpoch 37/100\n359/359 [==============================] - 345s 961ms/step - loss: 0.0241 - accuracy: 0.3601 - val_loss: 0.0239 - val_accuracy: 0.3589 - lr: 0.0100\nEpoch 38/100\n359/359 [==============================] - 341s 950ms/step - loss: 0.0239 - accuracy: 0.3725 - val_loss: 0.0234 - val_accuracy: 0.3897 - lr: 0.0100\nEpoch 39/100\n359/359 [==============================] - 338s 940ms/step - loss: 0.0239 - accuracy: 0.3673 - val_loss: 0.0234 - val_accuracy: 0.4029 - lr: 0.0100\nEpoch 40/100\n359/359 [==============================] - 338s 940ms/step - loss: 0.0238 - accuracy: 0.3722 - val_loss: 0.0234 - val_accuracy: 0.4022 - lr: 0.0100\nEpoch 41/100\n359/359 [==============================] - 342s 951ms/step - loss: 0.0237 - accuracy: 0.3732 - val_loss: 0.0235 - val_accuracy: 0.3617 - lr: 0.0100\nEpoch 42/100\n359/359 [==============================] - 339s 943ms/step - loss: 0.0236 - accuracy: 0.3747 - val_loss: 0.0235 - val_accuracy: 0.3568 - lr: 0.0100\nEpoch 43/100\n359/359 [==============================] - 332s 924ms/step - loss: 0.0236 - accuracy: 0.3796 - val_loss: 0.0237 - val_accuracy: 0.3750 - lr: 0.0100\nEpoch 44/100\n359/359 [==============================] - 329s 916ms/step - loss: 0.0234 - accuracy: 0.3807 - val_loss: 0.0234 - val_accuracy: 0.3701 - lr: 0.0100\nEpoch 45/100\n359/359 [==============================] - 333s 928ms/step - loss: 0.0232 - accuracy: 0.3846 - val_loss: 0.0244 - val_accuracy: 0.3191 - lr: 0.0100\nEpoch 46/100\n359/359 [==============================] - 331s 921ms/step - loss: 0.0232 - accuracy: 0.3782 - val_loss: 0.0235 - val_accuracy: 0.3652 - lr: 0.0100\nEpoch 47/100\n359/359 [==============================] - 329s 917ms/step - loss: 0.0230 - accuracy: 0.3860 - val_loss: 0.0230 - val_accuracy: 0.3939 - lr: 0.0100\nEpoch 48/100\n359/359 [==============================] - 337s 939ms/step - loss: 0.0229 - accuracy: 0.3887 - val_loss: 0.0236 - val_accuracy: 0.3883 - lr: 0.0100\nEpoch 49/100\n359/359 [==============================] - 345s 962ms/step - loss: 0.0227 - accuracy: 0.3890 - val_loss: 0.0226 - val_accuracy: 0.4127 - lr: 0.0100\nEpoch 50/100\n359/359 [==============================] - 341s 948ms/step - loss: 0.0226 - accuracy: 0.3962 - val_loss: 0.0239 - val_accuracy: 0.3876 - lr: 0.0100\nEpoch 51/100\n359/359 [==============================] - 329s 916ms/step - loss: 0.0224 - accuracy: 0.4028 - val_loss: 0.0231 - val_accuracy: 0.3946 - lr: 0.0100\nEpoch 52/100\n359/359 [==============================] - 327s 911ms/step - loss: 0.0222 - accuracy: 0.4077 - val_loss: 0.0232 - val_accuracy: 0.3946 - lr: 0.0100\nEpoch 53/100\n359/359 [==============================] - 332s 925ms/step - loss: 0.0221 - accuracy: 0.4118 - val_loss: 0.0246 - val_accuracy: 0.3282 - lr: 0.0100\nEpoch 54/100\n359/359 [==============================] - 334s 929ms/step - loss: 0.0222 - accuracy: 0.4163 - val_loss: 0.0230 - val_accuracy: 0.4204 - lr: 0.0100\nEpoch 55/100\n359/359 [==============================] - 329s 916ms/step - loss: 0.0220 - accuracy: 0.4158 - val_loss: 0.0229 - val_accuracy: 0.4001 - lr: 0.0100\nEpoch 56/100\n359/359 [==============================] - 331s 923ms/step - loss: 0.0219 - accuracy: 0.4180 - val_loss: 0.0226 - val_accuracy: 0.4295 - lr: 0.0100\nEpoch 57/100\n359/359 [==============================] - 328s 914ms/step - loss: 0.0218 - accuracy: 0.4186 - val_loss: 0.0222 - val_accuracy: 0.4420 - lr: 0.0100\nEpoch 58/100\n359/359 [==============================] - 331s 922ms/step - loss: 0.0217 - accuracy: 0.4223 - val_loss: 0.0271 - val_accuracy: 0.3135 - lr: 0.0100\nEpoch 59/100\n359/359 [==============================] - 331s 922ms/step - loss: 0.0216 - accuracy: 0.4306 - val_loss: 0.0245 - val_accuracy: 0.4078 - lr: 0.0100\nEpoch 60/100\n359/359 [==============================] - 331s 922ms/step - loss: 0.0216 - accuracy: 0.4278 - val_loss: 0.0247 - val_accuracy: 0.3547 - lr: 0.0100\nEpoch 61/100\n359/359 [==============================] - 336s 935ms/step - loss: 0.0214 - accuracy: 0.4344 - val_loss: 0.0221 - val_accuracy: 0.4497 - lr: 0.0100\nEpoch 62/100\n359/359 [==============================] - 335s 932ms/step - loss: 0.0214 - accuracy: 0.4346 - val_loss: 0.0236 - val_accuracy: 0.3973 - lr: 0.0100\nEpoch 63/100\n359/359 [==============================] - 332s 924ms/step - loss: 0.0212 - accuracy: 0.4394 - val_loss: 0.0252 - val_accuracy: 0.3610 - lr: 0.0100\nEpoch 64/100\n359/359 [==============================] - 331s 920ms/step - loss: 0.0211 - accuracy: 0.4405 - val_loss: 0.0233 - val_accuracy: 0.4078 - lr: 0.0100\nEpoch 65/100\n359/359 [==============================] - 332s 924ms/step - loss: 0.0212 - accuracy: 0.4404 - val_loss: 0.0227 - val_accuracy: 0.4295 - lr: 0.0100\nEpoch 66/100\n359/359 [==============================] - 329s 916ms/step - loss: 0.0211 - accuracy: 0.4433 - val_loss: 0.0228 - val_accuracy: 0.4462 - lr: 0.0100\nEpoch 67/100\n359/359 [==============================] - 330s 918ms/step - loss: 0.0209 - accuracy: 0.4528 - val_loss: 0.0221 - val_accuracy: 0.4504 - lr: 0.0100\nEpoch 68/100\n359/359 [==============================] - 339s 944ms/step - loss: 0.0209 - accuracy: 0.4478 - val_loss: 0.0224 - val_accuracy: 0.4448 - lr: 0.0100\nEpoch 69/100\n359/359 [==============================] - 345s 962ms/step - loss: 0.0208 - accuracy: 0.4526 - val_loss: 0.0235 - val_accuracy: 0.4078 - lr: 0.0100\nEpoch 70/100\n359/359 [==============================] - 342s 953ms/step - loss: 0.0208 - accuracy: 0.4545 - val_loss: 0.0221 - val_accuracy: 0.4581 - lr: 0.0100\nEpoch 71/100\n359/359 [==============================] - 343s 954ms/step - loss: 0.0208 - accuracy: 0.4545 - val_loss: 0.0219 - val_accuracy: 0.4679 - lr: 0.0100\nEpoch 72/100\n359/359 [==============================] - 340s 945ms/step - loss: 0.0205 - accuracy: 0.4632 - val_loss: 0.0230 - val_accuracy: 0.4427 - lr: 0.0100\nEpoch 73/100\n359/359 [==============================] - 341s 949ms/step - loss: 0.0206 - accuracy: 0.4596 - val_loss: 0.0215 - val_accuracy: 0.4825 - lr: 0.0100\nEpoch 74/100\n359/359 [==============================] - 341s 949ms/step - loss: 0.0206 - accuracy: 0.4643 - val_loss: 0.0230 - val_accuracy: 0.4134 - lr: 0.0100\nEpoch 75/100\n359/359 [==============================] - 338s 940ms/step - loss: 0.0205 - accuracy: 0.4660 - val_loss: 0.0217 - val_accuracy: 0.4532 - lr: 0.0100\nEpoch 76/100\n359/359 [==============================] - 345s 959ms/step - loss: 0.0202 - accuracy: 0.4716 - val_loss: 0.0214 - val_accuracy: 0.4602 - lr: 0.0100\nEpoch 77/100\n359/359 [==============================] - 342s 953ms/step - loss: 0.0204 - accuracy: 0.4683 - val_loss: 0.0221 - val_accuracy: 0.4448 - lr: 0.0100\nEpoch 78/100\n359/359 [==============================] - 342s 953ms/step - loss: 0.0202 - accuracy: 0.4708 - val_loss: 0.0226 - val_accuracy: 0.4295 - lr: 0.0100\nEpoch 79/100\n359/359 [==============================] - 342s 952ms/step - loss: 0.0202 - accuracy: 0.4761 - val_loss: 0.0226 - val_accuracy: 0.4553 - lr: 0.0100\nEpoch 80/100\n359/359 [==============================] - 343s 954ms/step - loss: 0.0201 - accuracy: 0.4811 - val_loss: 0.0213 - val_accuracy: 0.4958 - lr: 0.0100\nEpoch 81/100\n359/359 [==============================] - 340s 945ms/step - loss: 0.0201 - accuracy: 0.4801 - val_loss: 0.0220 - val_accuracy: 0.4693 - lr: 0.0100\nEpoch 82/100\n359/359 [==============================] - 345s 959ms/step - loss: 0.0199 - accuracy: 0.4837 - val_loss: 0.0223 - val_accuracy: 0.4378 - lr: 0.0100\nEpoch 83/100\n359/359 [==============================] - 342s 951ms/step - loss: 0.0201 - accuracy: 0.4777 - val_loss: 0.0214 - val_accuracy: 0.4881 - lr: 0.0100\nEpoch 84/100\n359/359 [==============================] - 346s 963ms/step - loss: 0.0199 - accuracy: 0.4846 - val_loss: 0.0221 - val_accuracy: 0.4749 - lr: 0.0100\nEpoch 85/100\n359/359 [==============================] - 344s 957ms/step - loss: 0.0198 - accuracy: 0.4896 - val_loss: 0.0225 - val_accuracy: 0.4413 - lr: 0.0100\nEpoch 86/100\n359/359 [==============================] - 347s 966ms/step - loss: 0.0197 - accuracy: 0.4899 - val_loss: 0.0226 - val_accuracy: 0.4483 - lr: 0.0100\nEpoch 87/100\n359/359 [==============================] - 347s 965ms/step - loss: 0.0197 - accuracy: 0.4923 - val_loss: 0.0213 - val_accuracy: 0.4777 - lr: 0.0100\nEpoch 88/100\n359/359 [==============================] - 345s 959ms/step - loss: 0.0197 - accuracy: 0.4909 - val_loss: 0.0217 - val_accuracy: 0.4714 - lr: 0.0100\nEpoch 89/100\n359/359 [==============================] - 344s 956ms/step - loss: 0.0197 - accuracy: 0.4935 - val_loss: 0.0220 - val_accuracy: 0.4609 - lr: 0.0100\nEpoch 90/100\n359/359 [==============================] - 347s 965ms/step - loss: 0.0196 - accuracy: 0.4934 - val_loss: 0.0222 - val_accuracy: 0.4742 - lr: 0.0100\nEpoch 91/100\n359/359 [==============================] - 346s 962ms/step - loss: 0.0192 - accuracy: 0.5050 - val_loss: 0.0209 - val_accuracy: 0.4937 - lr: 0.0050\nEpoch 92/100\n359/359 [==============================] - 351s 976ms/step - loss: 0.0190 - accuracy: 0.5098 - val_loss: 0.0207 - val_accuracy: 0.5077 - lr: 0.0050\nEpoch 93/100\n359/359 [==============================] - 344s 957ms/step - loss: 0.0190 - accuracy: 0.5095 - val_loss: 0.0217 - val_accuracy: 0.4804 - lr: 0.0050\nEpoch 94/100\n359/359 [==============================] - 344s 958ms/step - loss: 0.0189 - accuracy: 0.5135 - val_loss: 0.0209 - val_accuracy: 0.4895 - lr: 0.0050\nEpoch 95/100\n359/359 [==============================] - 346s 964ms/step - loss: 0.0188 - accuracy: 0.5164 - val_loss: 0.0212 - val_accuracy: 0.5133 - lr: 0.0050\nEpoch 96/100\n359/359 [==============================] - 346s 962ms/step - loss: 0.0188 - accuracy: 0.5134 - val_loss: 0.0210 - val_accuracy: 0.5028 - lr: 0.0050\nEpoch 97/100\n359/359 [==============================] - 350s 974ms/step - loss: 0.0188 - accuracy: 0.5185 - val_loss: 0.0211 - val_accuracy: 0.5070 - lr: 0.0050\nEpoch 98/100\n359/359 [==============================] - 349s 970ms/step - loss: 0.0187 - accuracy: 0.5228 - val_loss: 0.0209 - val_accuracy: 0.5021 - lr: 0.0050\nEpoch 99/100\n359/359 [==============================] - 346s 962ms/step - loss: 0.0186 - accuracy: 0.5211 - val_loss: 0.0217 - val_accuracy: 0.4811 - lr: 0.0050\nEpoch 100/100\n359/359 [==============================] - 349s 971ms/step - loss: 0.0186 - accuracy: 0.5224 - val_loss: 0.0204 - val_accuracy: 0.5049 - lr: 0.0050\n359/359 [==============================] - 336s 935ms/step\n23/23 [==============================] - 4s 196ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Predict and evaluate the model using validation data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m rf_classifier\u001b[38;5;241m.\u001b[39mpredict(val_features)\n\u001b[0;32m---> 22\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(lbl, val_predictions)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Visualize the model performance\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"],"ename":"NameError","evalue":"name 'accuracy_score' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# CenterLoss(0.01)\nmodel.save('Mobilenet_2.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T18:53:37.109584Z","iopub.execute_input":"2023-10-25T18:53:37.109971Z","iopub.status.idle":"2023-10-25T18:53:37.622050Z","shell.execute_reply.started":"2023-10-25T18:53:37.109940Z","shell.execute_reply":"2023-10-25T18:53:37.621033Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-10-25T11:29:26.556646Z","iopub.execute_input":"2023-10-25T11:29:26.557340Z","iopub.status.idle":"2023-10-25T11:29:27.568715Z","shell.execute_reply.started":"2023-10-25T11:29:26.557305Z","shell.execute_reply":"2023-10-25T11:29:27.567356Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'Mobilenet_2.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T18:53:46.490111Z","iopub.execute_input":"2023-10-25T18:53:46.491017Z","iopub.status.idle":"2023-10-25T18:53:46.496745Z","shell.execute_reply.started":"2023-10-25T18:53:46.490982Z","shell.execute_reply":"2023-10-25T18:53:46.495894Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/Mobilenet_2.h5","text/html":"<a href='Mobilenet_2.h5' target='_blank'>Mobilenet_2.h5</a><br>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"model_archive\", \"zip\", \"/kaggle/working/PAtt_Lite\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T11:06:21.535831Z","iopub.execute_input":"2023-09-20T11:06:21.536191Z","iopub.status.idle":"2023-09-20T11:06:22.834241Z","shell.execute_reply.started":"2023-09-20T11:06:21.536162Z","shell.execute_reply":"2023-09-20T11:06:22.827764Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/model_archive.zip'"},"metadata":{}}],"execution_count":22}]}